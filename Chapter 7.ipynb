{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tf",
   "display_name": "tf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test-Error: 1.146 Test-Accuracy: 0.1529\n Test-Error: 1.496 Test-Accuracy: 0.1142\n Test-Error: 1.539 Test-Accuracy: 0.108\n Test-Error: 1.547 Test-Accuracy: 0.1072\n Test-Error: 1.556 Test-Accuracy: 0.1066\n Test-Error: 1.564 Test-Accuracy: 0.1073\n Test-Error: 1.572 Test-Accuracy: 0.1076\n Test-Error: 1.583 Test-Accuracy: 0.1077\n Test-Error: 1.593 Test-Accuracy: 0.108\n Test-Error: 1.604 Test-Accuracy: 0.1081\n Test-Error: 1.616 Test-Accuracy: 0.1078\n Test-Error: 1.628 Test-Accuracy: 0.1073\n Test-Error: 1.639 Test-Accuracy: 0.1072\n Test-Error: 1.650 Test-Accuracy: 0.1071\n Test-Error: 1.659 Test-Accuracy: 0.1069\n Test-Error: 1.668 Test-Accuracy: 0.1068\n Test-Error: 1.676 Test-Accuracy: 0.1072\n Test-Error: 1.683 Test-Accuracy: 0.1069\n Test-Error: 1.689 Test-Accuracy: 0.1075\n Test-Error: 1.694 Test-Accuracy: 0.108\n Test-Error: 1.701 Test-Accuracy: 0.1088\n Test-Error: 1.710 Test-Accuracy: 0.1098\n Test-Error: 1.720 Test-Accuracy: 0.1109\n Test-Error: 1.730 Test-Accuracy: 0.112\n Test-Error: 1.741 Test-Accuracy: 0.1127\n Test-Error: 1.751 Test-Accuracy: 0.1137\n Test-Error: 1.758 Test-Accuracy: 0.1146\n Test-Error: 1.763 Test-Accuracy: 0.1158\n Test-Error: 1.767 Test-Accuracy: 0.1169\n Test-Error: 1.769 Test-Accuracy: 0.1182\n Test-Error: 1.771 Test-Accuracy: 0.1196\n Test-Error: 1.774 Test-Accuracy: 0.1209\n Test-Error: 1.777 Test-Accuracy: 0.1216\n Test-Error: 1.780 Test-Accuracy: 0.1233\n Test-Error: 1.782 Test-Accuracy: 0.1251\n Test-Error: 1.785 Test-Accuracy: 0.1274\n"
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28)/255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][1] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x: (x>=0) * x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    #sys.stdout.write(\"\\r\" + \" I: \" + str(j) + \" Error: \" + str(error/float(len(images)))[0:5] + \" Correct: \" + str(correct_cnt/float(len(images))))\n",
    "\n",
    "    if(j % 10 == 0 or j == iterations-1):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            error += np.sum((test_labels[i:i+1] - layer_2) ** 2 )\n",
    "            correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "        sys.stdout.write(\" Test-Error: \" + str(error/float(len(test_images)))[0:5] + \" Test-Accuracy: \" + str(correct_cnt/float(len(test_images))))\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " I: 349 Error: 1.129 Correct: 0.115"
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "\n",
    "for i, l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28)/255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i, l in enumerate(y_test):\n",
    "    test_labels[i][1] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x: (x>=0) * x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 100, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_1 += dropout_mask * 2\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        layer_1_delta *- dropout_mask\n",
    "\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    if(j % 10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) - np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "    sys.stdout.write(\"\\r\" + \" I: \" + str(j) + \" Error: \" + str(error/float(len(images)))[0:5] + \" Correct: \" + str(correct_cnt/float(len(images))))"
   ]
  }
 ]
}